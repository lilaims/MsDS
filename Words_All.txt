Bayesian Statistics
Posterior

Probability Theory
Classical , Frequency , Axiomatic - rules based 
Conditional Probability
Probability Distributions
Combinatorics

Estimators
Moment
Moment Generating Functions
Mean , Median , Mode
Variance , Co Variance
Corelation 
Convolution
Skewed , Symmetry 
Kurtosis

Discrete
Uniform , Bernoulli , Binomial , Geometric ,
Hyper Geometric ,  Poisson 

Continuous
Normal , Chisquared , T 

Random Variables
Sampling
Counting
Arrangement

Probability Density Function



Circular Permutations

Distances

Types of Data 
Categorical , Ordinal , Nominal


Disimilarity Matrix

Categorical 
Categorical Storage
Encoding Categorical
One hot encoders , Binary Encoding , 

Gamma Distribution
Gamma Function 
Exponential Distribution
Beta Distribution

univariate , Biviriate , Multivariate
___________________________________________________________________________________________________
Learning
Supervised , Unsupervised, Reinforcement

Generative, Predictive

SSSE , MSE , MAE
|y-yi| , |y-yi|^2 , |y-yi|

cosine x T . y/ |x||y|

Polynomial regression
Hyperparameter

the question is why cant the function too have many to one mpping , wont it have something missing.

***
one to one mapping , one to many mapping is fine
??but many to one mapping is not fine but fine in machine learning
dataset its possible but not in the model
like the poker problem

??Probability density vs Probability distribution

Latent Space
___________________________________________________________________________________________________
Data Visualization
Plots
Seaborn

histogram 
whisker 
continuous 
discrete


time 
frequency 
quantity
probability
normalised
density


